---
title: 'smolagents+ollama: æ‰“é€ é«˜åº¦å®šåˆ¶åŒ–å¯è”ç½‘çš„ç§åŸŸagent'
tags: ['smolagents', 'huggingface', 'agent', 'ollama']
categories: ['å®æˆ˜', 'ollama', 'å¤§æ¨¡å‹', 'python3', 'deepseek']
series: ['llm']
author: ['zhu733756']
date: 2025-02-19T09:24:25+08:00
---

## å‰æˆ

> ä»Šå¤©æˆ‘ä»¬èŠèŠä½¿ç”¨ smolagents + ollama æ‰“é€ æœ¬åœ°ç§åŸŸå¯è”ç½‘ agent

## ğŸŒŸ é¡¹ç›®ç®€ä»‹

> https://github.com/huggingface/smolagents

smolagents æ˜¯ä¸€ä¸ªè½»é‡çº§åº“, ç”¨äºæ„å»ºå¼ºå¤§çš„ä»£ç†(agents)ã€‚å®ƒå…è®¸ç”¨æˆ·é€šè¿‡å‡ è¡Œä»£ç è¿è¡ŒåŠŸèƒ½å¼ºå¤§çš„ä»£ç†,æ”¯æŒå¤šç§è¯­è¨€æ¨¡å‹(LLM)å’Œå·¥å…·ã€‚ä»£ç†å¯ä»¥é€šè¿‡ç¼–å†™ Python ä»£ç æ¥è°ƒç”¨å·¥å…·å¹¶åè°ƒå…¶ä»–ä»£ç†,éå¸¸é€‚åˆå¿«é€Ÿå¼€å‘å’Œéƒ¨ç½²æ™ºèƒ½ä»£ç†ç³»ç»Ÿã€‚

![smolagents](/posts/llm_agents/smolagents.png)

## ğŸš€ åŠŸèƒ½ç‰¹ç‚¹

- æç®€è®¾è®¡:ä»£ç†çš„æ ¸å¿ƒé€»è¾‘ä»…çº¦ 1000 è¡Œä»£ç ,ä¿æŒæœ€å°åŒ–çš„æŠ½è±¡å±‚ã€‚

- æ”¯æŒä»£ç ä»£ç† CodeAgent :é€šè¿‡ä»£ç æ‰§è¡ŒåŠ¨ä½œ,æ”¯æŒåœ¨æ²™ç›’ç¯å¢ƒä¸­è¿è¡Œä»¥ç¡®ä¿å®‰å…¨æ€§

- é›†æˆ Hugging Face Hub:æ”¯æŒä» Hub å…±äº«å’Œæ‹‰å–å·¥å…·ã€‚

- æ¨¡å‹æ— å…³æ€§:æ”¯æŒä»»ä½• LLMã€‚

- å¤šæ¨¡æ€æ”¯æŒ:æ”¯æŒæ–‡æœ¬ã€è§†è§‰ã€è§†é¢‘ç”šè‡³éŸ³é¢‘è¾“å…¥ã€‚

- å·¥å…·æ— å…³æ€§:æ”¯æŒ LangChainã€Anthropic çš„ MCP ç­‰å·¥å…·,ç”šè‡³å¯ä»¥å°† Hub Space ä½œä¸ºå·¥å…·ä½¿ç”¨ã€‚

## ğŸ› ï¸ éƒ¨ç½²ä½¿ç”¨æŒ‡å—

### ğŸ“¦ å®‰è£…

é€šè¿‡ pip å®‰è£… smolagents:

```bash
pip install smolagents
```

å‹æƒ…æç¤º: æœ¬åœ°çš„ python ç‰ˆæœ¬è¦æ±‚>=3.10

ä½ å¯ä»¥å‚è€ƒè¿™ä¸ªæ–¹å¼è¿›è¡Œå‡çº§:

```bash
sudo add-apt-repository ppa:deadsnakes/ppa
sudo apt update
sudo apt install python3.10
python3.10 --version

# Python 3.10 é»˜è®¤å¯èƒ½ä¸å¸¦ pip,éœ€è¦æ‰‹åŠ¨å®‰è£…:
sudo apt install python3.10-distutils
curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py
python3.10 get-pip.py

# é…ç½®python3.10 ä¸ºpython3é»˜è®¤ç‰ˆæœ¬
sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 1
sudo update-alternatives --config python3
```

## ğŸŒ æ”¯æŒçš„æ¨¡å‹å’Œå·¥å…·

- HfApiModel:æ”¯æŒ Hugging Face Hub ä¸Šçš„æ¨¡å‹ã€‚
- LiteLLMModel:é€šè¿‡ LiteLLM é›†æˆè®¿é—® 100+ LLMã€‚
- OpenAIServerModel:æ”¯æŒ OpenAI å…¼å®¹çš„æœåŠ¡å™¨ã€‚
- TransformersModel:æ”¯æŒæœ¬åœ° transformers æ¨¡å‹ã€‚
- AzureOpenAIServerModel:æ”¯æŒ Azure ä¸Šçš„ OpenAI æ¨¡å‹ã€‚

## ğŸ“Ÿ CLI å·¥å…·

smolagents æä¾›äº†ä¸¤ä¸ª CLI å‘½ä»¤:smolagent å’Œ webagentã€‚

### smolagents

smolagent:è¿è¡Œå¤šæ­¥éª¤çš„ CodeAgent,æ”¯æŒå¤šç§å·¥å…·ã€‚

```bash
smolagent "Plan a trip to Tokyo, Kyoto and Osaka between Mar 28 and Apr 7." --model-type "HfApiModel" --model-id "Qwen/Qwen2.5-Coder-32B-Instruct" --imports "pandas numpy" --tools "web_search translation"
```

### webagent

webagent:ä¸“é—¨ç”¨äºç½‘é¡µæµè§ˆçš„ä»£ç†ã€‚

```bash
webagent "go to xyz.com/men, get to sale section, click the first clothing item you see. Get the product details, and the price, return them. note that I'm shopping from France" --model-type "LiteLLMModel" --model-id "gpt-4o"
```

## ğŸš€ é›†æˆ ollama agent ç¤ºä¾‹

### 1. åˆ›å»ºä¸€ä¸ª DuckDuckGo æœç´¢ agent

```python
from smolagents import CodeAgent, LiteLLMModel, DuckDuckGoSearchTool
from litellm import LiteLLM

# é…ç½® Ollama æ¨¡å‹
model = LiteLLMModel(
    model_id="ollama_chat/deepseek-r1:7b", # æ ¼å¼æ˜¯ollama_chat/xxx
    base_url="http://192.168.137.112:11434",
    api_key=None, # é»˜è®¤ä¸º None
    num_ctx=8192
)

# æ·»åŠ å·¥å…·
tools = [DuckDuckGoSearchTool()]  # æ·»åŠ  DuckDuckGo æœç´¢å·¥å…·

# åˆå§‹åŒ– SmolAgents çš„ CodeAgent
agent = CodeAgent(tools=tools, model=model, add_base_tools=True)

# æµ‹è¯•æ™ºèƒ½ä½“
output = agent.run("What is the latest news about AI?")
print("Final output:")
print(output)
```

### 2. åˆ›å»ºä¸€ä¸ªå¤šæœç´¢ agent

```python
from smolagents import (
    CodeAgent,
    LiteLLMModel,
    DuckDuckGoSearchTool,
    ToolCallingAgent,
    VisitWebpageTool,
)


model = LiteLLMModel(
    model_id="ollama_chat/deepseek-r1:7b", # æ ¼å¼æ˜¯ollama_chat/xxx
    base_url="http://192.168.137.112:11434",
    api_key=None, # é»˜è®¤ä¸º None
    num_ctx=8192
)

search_agent = ToolCallingAgent(
    tools=[DuckDuckGoSearchTool(), VisitWebpageTool()],
    model=model,
    name="search_agent",
    description="This is an agent that can do web search.",
)

manager_agent = CodeAgent(
    tools=[],
    model=model,
    managed_agents=[search_agent],
)
manager_agent.run("If the US keeps it 2024 growth rate, how many years would it take for the GDP to double?")
```

### 3. åˆ›å»ºä¸€ä¸ª rag

> https://github.com/huggingface/smolagents/blob/main/examples/rag_using_chromadb.py

```python
import os

import datasets
from langchain.docstore.document import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_chroma import Chroma

# from langchain_community.document_loaders import PyPDFLoader
from langchain_huggingface import HuggingFaceEmbeddings
from tqdm import tqdm
from transformers import AutoTokenizer

# from langchain_openai import OpenAIEmbeddings
from smolagents import LiteLLMModel, Tool
from smolagents.agents import CodeAgent


# from smolagents.agents import ToolCallingAgent


knowledge_base = datasets.load_dataset("m-ric/huggingface_doc", split="train")

source_docs = [
    Document(page_content=doc["text"], metadata={"source": doc["source"].split("/")[1]}) for doc in knowledge_base
]

## For your own PDFs, you can use the following code to load them into source_docs
# pdf_directory = "pdfs"
# pdf_files = [
#     os.path.join(pdf_directory, f)
#     for f in os.listdir(pdf_directory)
#     if f.endswith(".pdf")
# ]
# source_docs = []

# for file_path in pdf_files:
#     loader = PyPDFLoader(file_path)
#     docs.extend(loader.load())

text_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(
    AutoTokenizer.from_pretrained("thenlper/gte-small"),
    chunk_size=200,
    chunk_overlap=20,
    add_start_index=True,
    strip_whitespace=True,
    separators=["\n\n", "\n", ".", " ", ""],
)

# Split docs and keep only unique ones
print("Splitting documents...")
docs_processed = []
unique_texts = {}
for doc in tqdm(source_docs):
    new_docs = text_splitter.split_documents([doc])
    for new_doc in new_docs:
        if new_doc.page_content not in unique_texts:
            unique_texts[new_doc.page_content] = True
            docs_processed.append(new_doc)


print("Embedding documents... This should take a few minutes (5 minutes on MacBook with M1 Pro)")
# Initialize embeddings and ChromaDB vector store
embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")


# embeddings = OpenAIEmbeddings(model="text-embedding-3-small")

vector_store = Chroma.from_documents(docs_processed, embeddings, persist_directory="./chroma_db")


class RetrieverTool(Tool):
    name = "retriever"
    description = (
        "Uses semantic search to retrieve the parts of documentation that could be most relevant to answer your query."
    )
    inputs = {
        "query": {
            "type": "string",
            "description": "The query to perform. This should be semantically close to your target documents. Use the affirmative form rather than a question.",
        }
    }
    output_type = "string"

    def __init__(self, vector_store, **kwargs):
        super().__init__(**kwargs)
        self.vector_store = vector_store

    def forward(self, query: str) -> str:
        assert isinstance(query, str), "Your search query must be a string"
        docs = self.vector_store.similarity_search(query, k=3)
        return "\nRetrieved documents:\n" + "".join(
            [f"\n\n===== Document {str(i)} =====\n" + doc.page_content for i, doc in enumerate(docs)]
        )


retriever_tool = RetrieverTool(vector_store)

# Choose which LLM engine to use!

# from smolagents import HfApiModel
# model = HfApiModel(model_id="meta-llama/Llama-3.3-70B-Instruct")

# from smolagents import TransformersModel
# model = TransformersModel(model_id="meta-llama/Llama-3.2-2B-Instruct")

# For anthropic: change model_id below to 'anthropic/claude-3-5-sonnet-20240620' and also change 'os.environ.get("ANTHROPIC_API_KEY")'
model = LiteLLMModel(
    model_id="groq/llama-3.3-70b-versatile",
    api_key=os.environ.get("GROQ_API_KEY"),
)

# # You can also use the ToolCallingAgent class
# agent = ToolCallingAgent(
#     tools=[retriever_tool],
#     model=model,
#     verbose=True,
# )

agent = CodeAgent(
    tools=[retriever_tool],
    model=model,
    max_steps=4,
    verbosity_level=2,
)

agent_output = agent.run("How can I push a model to the Hub?")


print("Final output:")
print(agent_output)
```

### 4.è‡ªå®šä¹‰åšå®¢å†™ä½œ

> https://github.com/zhu733756/cloud-database-tools/tree/master/llm/agents/smoleagents-examples

## å°å°¾å·´

ä»Šå¤©æˆ‘ä»¬ä½¿ç”¨ ollama + deepseek + smolagents ç»™å‡ºäº†ä¸€ç³»åˆ—ç¦»çº¿ ai ä»£ç†çš„ä»£ç ç¤ºä¾‹, è¿˜æ˜¯æŒºç®€å•çš„ï¼
